{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "papermill": {
      "duration": 8.960967,
      "end_time": "2020-10-22T16:47:34.103301",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-10-22T16:47:25.142334",
      "version": "2.1.0"
    },
    "colab": {
      "name": "logistic-regression-with-breast-cancer-data.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddhant-K-code/Logistic_Regression_with_Breast_Cancer_Data/blob/main/logistic_regression_with_breast_cancer_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:30.167248Z",
          "iopub.status.busy": "2020-10-22T16:47:30.166455Z",
          "iopub.status.idle": "2020-10-22T16:47:30.239624Z",
          "shell.execute_reply": "2020-10-22T16:47:30.240245Z"
        },
        "id": "-0hGaBrF48Ue",
        "papermill": {
          "duration": 0.106614,
          "end_time": "2020-10-22T16:47:30.240435",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.133821",
          "status": "completed"
        },
        "tags": [],
        "outputId": "23a454d4-dedb-4aaf-bb7e-4777023e4dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "source": [
        "# Reading the Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reading the Data\n",
        "data = pd.read_csv('./data.csv')\n",
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.049040</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.040060</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.020580</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.074580</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.024610</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>843786</td>\n",
              "      <td>M</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.033450</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.011370</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.17410</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>844359</td>\n",
              "      <td>M</td>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.013820</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.010390</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84458202</td>\n",
              "      <td>M</td>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.014480</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.15560</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>844981</td>\n",
              "      <td>M</td>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.035020</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.012260</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.20600</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>84501001</td>\n",
              "      <td>M</td>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.014320</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>845636</td>\n",
              "      <td>M</td>\n",
              "      <td>16.02</td>\n",
              "      <td>23.24</td>\n",
              "      <td>102.70</td>\n",
              "      <td>797.8</td>\n",
              "      <td>0.08206</td>\n",
              "      <td>0.06669</td>\n",
              "      <td>0.03299</td>\n",
              "      <td>0.03323</td>\n",
              "      <td>0.1528</td>\n",
              "      <td>0.05697</td>\n",
              "      <td>0.3795</td>\n",
              "      <td>1.1870</td>\n",
              "      <td>2.466</td>\n",
              "      <td>40.51</td>\n",
              "      <td>0.004029</td>\n",
              "      <td>0.009269</td>\n",
              "      <td>0.01101</td>\n",
              "      <td>0.007591</td>\n",
              "      <td>0.01460</td>\n",
              "      <td>0.003042</td>\n",
              "      <td>19.19</td>\n",
              "      <td>33.88</td>\n",
              "      <td>123.80</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>0.1181</td>\n",
              "      <td>0.1551</td>\n",
              "      <td>0.1459</td>\n",
              "      <td>0.09975</td>\n",
              "      <td>0.2948</td>\n",
              "      <td>0.08452</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>84610002</td>\n",
              "      <td>M</td>\n",
              "      <td>15.78</td>\n",
              "      <td>17.89</td>\n",
              "      <td>103.60</td>\n",
              "      <td>781.0</td>\n",
              "      <td>0.09710</td>\n",
              "      <td>0.12920</td>\n",
              "      <td>0.09954</td>\n",
              "      <td>0.06606</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>0.06082</td>\n",
              "      <td>0.5058</td>\n",
              "      <td>0.9849</td>\n",
              "      <td>3.564</td>\n",
              "      <td>54.16</td>\n",
              "      <td>0.005771</td>\n",
              "      <td>0.040610</td>\n",
              "      <td>0.02791</td>\n",
              "      <td>0.012820</td>\n",
              "      <td>0.02008</td>\n",
              "      <td>0.004144</td>\n",
              "      <td>20.42</td>\n",
              "      <td>27.28</td>\n",
              "      <td>136.50</td>\n",
              "      <td>1299.0</td>\n",
              "      <td>0.1396</td>\n",
              "      <td>0.5609</td>\n",
              "      <td>0.3965</td>\n",
              "      <td>0.18100</td>\n",
              "      <td>0.3792</td>\n",
              "      <td>0.10480</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>846226</td>\n",
              "      <td>M</td>\n",
              "      <td>19.17</td>\n",
              "      <td>24.80</td>\n",
              "      <td>132.40</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>0.09740</td>\n",
              "      <td>0.24580</td>\n",
              "      <td>0.20650</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07800</td>\n",
              "      <td>0.9555</td>\n",
              "      <td>3.5680</td>\n",
              "      <td>11.070</td>\n",
              "      <td>116.20</td>\n",
              "      <td>0.003139</td>\n",
              "      <td>0.082970</td>\n",
              "      <td>0.08890</td>\n",
              "      <td>0.040900</td>\n",
              "      <td>0.04484</td>\n",
              "      <td>0.012840</td>\n",
              "      <td>20.96</td>\n",
              "      <td>29.94</td>\n",
              "      <td>151.70</td>\n",
              "      <td>1332.0</td>\n",
              "      <td>0.1037</td>\n",
              "      <td>0.3903</td>\n",
              "      <td>0.3639</td>\n",
              "      <td>0.17670</td>\n",
              "      <td>0.3176</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>846381</td>\n",
              "      <td>M</td>\n",
              "      <td>15.85</td>\n",
              "      <td>23.95</td>\n",
              "      <td>103.70</td>\n",
              "      <td>782.7</td>\n",
              "      <td>0.08401</td>\n",
              "      <td>0.10020</td>\n",
              "      <td>0.09938</td>\n",
              "      <td>0.05364</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.05338</td>\n",
              "      <td>0.4033</td>\n",
              "      <td>1.0780</td>\n",
              "      <td>2.903</td>\n",
              "      <td>36.58</td>\n",
              "      <td>0.009769</td>\n",
              "      <td>0.031260</td>\n",
              "      <td>0.05051</td>\n",
              "      <td>0.019920</td>\n",
              "      <td>0.02981</td>\n",
              "      <td>0.003002</td>\n",
              "      <td>16.84</td>\n",
              "      <td>27.66</td>\n",
              "      <td>112.00</td>\n",
              "      <td>876.5</td>\n",
              "      <td>0.1131</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.2322</td>\n",
              "      <td>0.11190</td>\n",
              "      <td>0.2809</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>84667401</td>\n",
              "      <td>M</td>\n",
              "      <td>13.73</td>\n",
              "      <td>22.61</td>\n",
              "      <td>93.60</td>\n",
              "      <td>578.3</td>\n",
              "      <td>0.11310</td>\n",
              "      <td>0.22930</td>\n",
              "      <td>0.21280</td>\n",
              "      <td>0.08025</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.07682</td>\n",
              "      <td>0.2121</td>\n",
              "      <td>1.1690</td>\n",
              "      <td>2.061</td>\n",
              "      <td>19.21</td>\n",
              "      <td>0.006429</td>\n",
              "      <td>0.059360</td>\n",
              "      <td>0.05501</td>\n",
              "      <td>0.016280</td>\n",
              "      <td>0.01961</td>\n",
              "      <td>0.008093</td>\n",
              "      <td>15.03</td>\n",
              "      <td>32.01</td>\n",
              "      <td>108.80</td>\n",
              "      <td>697.7</td>\n",
              "      <td>0.1651</td>\n",
              "      <td>0.7725</td>\n",
              "      <td>0.6943</td>\n",
              "      <td>0.22080</td>\n",
              "      <td>0.3596</td>\n",
              "      <td>0.14310</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>84799002</td>\n",
              "      <td>M</td>\n",
              "      <td>14.54</td>\n",
              "      <td>27.54</td>\n",
              "      <td>96.73</td>\n",
              "      <td>658.8</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.16390</td>\n",
              "      <td>0.07364</td>\n",
              "      <td>0.2303</td>\n",
              "      <td>0.07077</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>1.0330</td>\n",
              "      <td>2.879</td>\n",
              "      <td>32.55</td>\n",
              "      <td>0.005607</td>\n",
              "      <td>0.042400</td>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.010900</td>\n",
              "      <td>0.01857</td>\n",
              "      <td>0.005466</td>\n",
              "      <td>17.46</td>\n",
              "      <td>37.13</td>\n",
              "      <td>124.10</td>\n",
              "      <td>943.2</td>\n",
              "      <td>0.1678</td>\n",
              "      <td>0.6577</td>\n",
              "      <td>0.7026</td>\n",
              "      <td>0.17120</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.13410</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>848406</td>\n",
              "      <td>M</td>\n",
              "      <td>14.68</td>\n",
              "      <td>20.13</td>\n",
              "      <td>94.74</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.09867</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.07395</td>\n",
              "      <td>0.05259</td>\n",
              "      <td>0.1586</td>\n",
              "      <td>0.05922</td>\n",
              "      <td>0.4727</td>\n",
              "      <td>1.2400</td>\n",
              "      <td>3.195</td>\n",
              "      <td>45.40</td>\n",
              "      <td>0.005718</td>\n",
              "      <td>0.011620</td>\n",
              "      <td>0.01998</td>\n",
              "      <td>0.011090</td>\n",
              "      <td>0.01410</td>\n",
              "      <td>0.002085</td>\n",
              "      <td>19.07</td>\n",
              "      <td>30.88</td>\n",
              "      <td>123.40</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.3029</td>\n",
              "      <td>0.08216</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>84862001</td>\n",
              "      <td>M</td>\n",
              "      <td>16.13</td>\n",
              "      <td>20.68</td>\n",
              "      <td>108.10</td>\n",
              "      <td>798.8</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.20220</td>\n",
              "      <td>0.17220</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>0.2164</td>\n",
              "      <td>0.07356</td>\n",
              "      <td>0.5692</td>\n",
              "      <td>1.0730</td>\n",
              "      <td>3.854</td>\n",
              "      <td>54.18</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.025010</td>\n",
              "      <td>0.03188</td>\n",
              "      <td>0.012970</td>\n",
              "      <td>0.01689</td>\n",
              "      <td>0.004142</td>\n",
              "      <td>20.96</td>\n",
              "      <td>31.48</td>\n",
              "      <td>136.80</td>\n",
              "      <td>1315.0</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>0.4233</td>\n",
              "      <td>0.4784</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>0.3706</td>\n",
              "      <td>0.11420</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>849014</td>\n",
              "      <td>M</td>\n",
              "      <td>19.81</td>\n",
              "      <td>22.15</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.09831</td>\n",
              "      <td>0.10270</td>\n",
              "      <td>0.14790</td>\n",
              "      <td>0.09498</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05395</td>\n",
              "      <td>0.7582</td>\n",
              "      <td>1.0170</td>\n",
              "      <td>5.865</td>\n",
              "      <td>112.40</td>\n",
              "      <td>0.006494</td>\n",
              "      <td>0.018930</td>\n",
              "      <td>0.03391</td>\n",
              "      <td>0.015210</td>\n",
              "      <td>0.01356</td>\n",
              "      <td>0.001997</td>\n",
              "      <td>27.32</td>\n",
              "      <td>30.88</td>\n",
              "      <td>186.80</td>\n",
              "      <td>2398.0</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.3150</td>\n",
              "      <td>0.5372</td>\n",
              "      <td>0.23880</td>\n",
              "      <td>0.2768</td>\n",
              "      <td>0.07615</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>8510426</td>\n",
              "      <td>B</td>\n",
              "      <td>13.54</td>\n",
              "      <td>14.36</td>\n",
              "      <td>87.46</td>\n",
              "      <td>566.3</td>\n",
              "      <td>0.09779</td>\n",
              "      <td>0.08129</td>\n",
              "      <td>0.06664</td>\n",
              "      <td>0.04781</td>\n",
              "      <td>0.1885</td>\n",
              "      <td>0.05766</td>\n",
              "      <td>0.2699</td>\n",
              "      <td>0.7886</td>\n",
              "      <td>2.058</td>\n",
              "      <td>23.56</td>\n",
              "      <td>0.008462</td>\n",
              "      <td>0.014600</td>\n",
              "      <td>0.02387</td>\n",
              "      <td>0.013150</td>\n",
              "      <td>0.01980</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>15.11</td>\n",
              "      <td>19.26</td>\n",
              "      <td>99.70</td>\n",
              "      <td>711.2</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1773</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.12880</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.07259</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0     842302         M  ...                  0.11890          NaN\n",
              "1     842517         M  ...                  0.08902          NaN\n",
              "2   84300903         M  ...                  0.08758          NaN\n",
              "3   84348301         M  ...                  0.17300          NaN\n",
              "4   84358402         M  ...                  0.07678          NaN\n",
              "5     843786         M  ...                  0.12440          NaN\n",
              "6     844359         M  ...                  0.08368          NaN\n",
              "7   84458202         M  ...                  0.11510          NaN\n",
              "8     844981         M  ...                  0.10720          NaN\n",
              "9   84501001         M  ...                  0.20750          NaN\n",
              "10    845636         M  ...                  0.08452          NaN\n",
              "11  84610002         M  ...                  0.10480          NaN\n",
              "12    846226         M  ...                  0.10230          NaN\n",
              "13    846381         M  ...                  0.06287          NaN\n",
              "14  84667401         M  ...                  0.14310          NaN\n",
              "15  84799002         M  ...                  0.13410          NaN\n",
              "16    848406         M  ...                  0.08216          NaN\n",
              "17  84862001         M  ...                  0.11420          NaN\n",
              "18    849014         M  ...                  0.07615          NaN\n",
              "19   8510426         B  ...                  0.07259          NaN\n",
              "\n",
              "[20 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UheCi8cf48Un",
        "papermill": {
          "duration": 0.016826,
          "end_time": "2020-10-22T16:47:30.275275",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.258449",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's have a look at the health of the data itself. This function `.info()` in the pandas library is very helpful to understand the basic properties of the data itself. If there is any missing values in the dataset can be known right from here so that they can be taken care of before fitting into a model for training and testing. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:30.330885Z",
          "iopub.status.busy": "2020-10-22T16:47:30.318544Z",
          "iopub.status.idle": "2020-10-22T16:47:30.335994Z",
          "shell.execute_reply": "2020-10-22T16:47:30.335156Z"
        },
        "id": "UL33cILW48Uo",
        "papermill": {
          "duration": 0.043635,
          "end_time": "2020-10-22T16:47:30.336191",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.292556",
          "status": "completed"
        },
        "tags": [],
        "outputId": "a7401725-68fe-4664-a51b-675993f42e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSh35FCx48Us",
        "papermill": {
          "duration": 0.017604,
          "end_time": "2020-10-22T16:47:30.372409",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.354805",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**There are 4 things that take my attention**\n",
        "\n",
        "1. There is an **`id`** that cannot be used for classificaiton \n",
        "2. **`Diagnosis`** column in the data is our class label\n",
        "3. **`Unnamed: 32`** feature includes **`NaN`** so we do not need it.\n",
        "4. I do not have any idea about other feature names actually.\n",
        "\n",
        "Therefore, drop these unnecessary features. However do not forget this is not a feature selection. This is like a browse a pub, we do not choose our drink yet !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:30.423719Z",
          "iopub.status.busy": "2020-10-22T16:47:30.422886Z",
          "iopub.status.idle": "2020-10-22T16:47:30.461521Z",
          "shell.execute_reply": "2020-10-22T16:47:30.460253Z"
        },
        "id": "r949QDzW48Us",
        "papermill": {
          "duration": 0.071386,
          "end_time": "2020-10-22T16:47:30.461673",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.390287",
          "status": "completed"
        },
        "tags": [],
        "outputId": "12ea7118-36ec-4464-8d63-08b2046e1ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "source": [
        "# feature names as a list\n",
        "# .columns gives columns names in data \n",
        "col = data.columns       \n",
        "print(col)\n",
        "\n",
        "\n",
        "data.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)\n",
        "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n",
        "y_data = data.diagnosis.values\n",
        "x_data = data.drop(['diagnosis'], axis=1)\n",
        "x_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0          17.99         10.38  ...          0.4601                  0.11890\n",
              "1          20.57         17.77  ...          0.2750                  0.08902\n",
              "2          19.69         21.25  ...          0.3613                  0.08758\n",
              "3          11.42         20.38  ...          0.6638                  0.17300\n",
              "4          20.29         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564        21.56         22.39  ...          0.2060                  0.07115\n",
              "565        20.13         28.25  ...          0.2572                  0.06637\n",
              "566        16.60         28.08  ...          0.2218                  0.07820\n",
              "567        20.60         29.33  ...          0.4087                  0.12400\n",
              "568         7.76         24.54  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZmPQ3qi48Uw",
        "papermill": {
          "duration": 0.019183,
          "end_time": "2020-10-22T16:47:30.500933",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.481750",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Okey, now we have features but **`what does they mean`** or actually **`how much do we need to know about these features`**\n",
        "The answer is that we do not need to know meaning of these features however in order to imagine in our mind we should know something like variance, standart deviation, number of sample (count) or max min values.\n",
        "These type of information helps to understand about what is going on data. For example , the question is appeared in my mind the **`area_mean`** feature's max value is 2500 and **`smoothness_mean`** features' max 0.16340. Therefore **do we need standirdization or normalization before visualization, feature selection, feature extraction or classificaiton?** The answer is yes and no not surprising ha :) Anyway lets go step by step and start with visualization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikmfvPcL48Ux",
        "papermill": {
          "duration": 0.01937,
          "end_time": "2020-10-22T16:47:30.540009",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.520639",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Normalization\n",
        "Normalization refers to rescaling real-valued numeric attributes into a 0 to 1 range. Data normalization is used in machine learning to make model training less sensitive to the scale of features.\n",
        "\n",
        "You can either implement the conversion process with basic python or use `MinMaxScaler()` function from the `sklearn` library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:30.587019Z",
          "iopub.status.busy": "2020-10-22T16:47:30.586265Z",
          "iopub.status.idle": "2020-10-22T16:47:31.646812Z",
          "shell.execute_reply": "2020-10-22T16:47:31.646126Z"
        },
        "id": "BZfZTspj48Ux",
        "papermill": {
          "duration": 1.087097,
          "end_time": "2020-10-22T16:47:31.646951",
          "exception": false,
          "start_time": "2020-10-22T16:47:30.559854",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Using transformer from sklearn library\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scalar = MinMaxScaler()\n",
        "output = scalar.fit_transform(x_data)\n",
        "\n",
        "# Manual Implementation of the normalization process\n",
        "X_data = (x_data -np.min(x_data))/ (np.max(x_data)-np.min(x_data)).values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faBBeeIw48U7",
        "papermill": {
          "duration": 0.019388,
          "end_time": "2020-10-22T16:47:31.687363",
          "exception": false,
          "start_time": "2020-10-22T16:47:31.667975",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## The Basics: Logistic Regression and Regularization\n",
        "\n",
        "Logistic Regression is one of the most common machine learning algorithms used for classification. It a statistical model that uses a logistic function to model a binary dependent variable. In essence, it predicts the probability of an observation belonging to a certain class or label. For instance, is this a cat photo or a dog photo?\n",
        "\n",
        "Ordinary Least Squares linear regression is powerful and versatile right out of the box, but there are certain circumstances where it fails. \n",
        "1. it is, expressly, a ‘regression’ framework, which makes it hard to apply as a classifier.\n",
        "2. unlike, say, a decision tree, linear regression models don’t perform their own implicit feature selection, meaning they are prone to overfit if too many features are included. \n",
        "\n",
        "Luckily, there are some extensions to the linear model that allow us to overcome these issues. Logistic regression turns the linear regression framework into a classifier and various types of **`regularization`** of which the `Ridge` and `Lasso` methods are most common, help avoid overfit in feature rich instances.\n",
        "\n",
        "### **Hypothesis:** \n",
        "We want our model to predict the probability of an observation belonging to a certain class or label. As such, we want a hypothesis $h$ that satisfies the following condition $0 <= h(x) <= 1$ , where $x$ is an observation.\n",
        "\n",
        "We define $h(x) = g(w^T * x)$ , where $g$ is a sigmoid function and $w$ are the trainable parameters or `weights`. As such, we have:\n",
        "$$h(x) = \\frac{1}{1+e^{-w^Tx}}$$\n",
        "\n",
        "### The cost for an observation: \n",
        "Now that we can predict the probability for an observation, we want the result to have the minimum error. If the class label is $y$, the cost (error) associated with an observation $x$ is given by:\n",
        "\n",
        "![](https://miro.medium.com/max/525/1*vSGnYVz6I7sAObKuxuFAoQ.gif)\n",
        "\n",
        "### Cost Function: \n",
        "Thus, the total cost for all the $m$ observations in a dataset is:\n",
        "![](https://miro.medium.com/max/368/0*vZnp94vCoN0vMDAj)\n",
        "\n",
        "We can rewrite the cost function J as:\n",
        "![](https://miro.medium.com/max/691/0*o57ug0iMGDJVI1qo)\n",
        "\n",
        "The objective of logistic regression is to find params `w` so that `J` is minimum. How can we do that?? We will use the gradient descent algorithm to update each of the weights gradually to minimize the cost `J`. \n",
        "\n",
        "We will update each of the params wᵢ using the following template:\n",
        "![](https://miro.medium.com/max/875/0*Q6ssvXABrvHUZrfy)\n",
        "![](https://miro.medium.com/max/496/0*7uVvuW-ZGauNWH_V)\n",
        "\n",
        "The above step will help us find a set of params wᵢ, which will then help us to come up with $h(x)$ to solve our binary classification task.\n",
        "But there is also an undesirable outcome associated with the above gradient descent steps. In an attempt to find the best $h(x)$, the following things happen:\n",
        "\n",
        "**CASE I: For class label = 0**: $h(x)$ will try to produce results as close 0 as possible. As such, $w^T.x$ will be as small as possible\n",
        "=> Wi will tend to -infinity\n",
        "\n",
        "**CASE II: For class label = 1**: $h(x)$ will try to produce results as close 1 as possible. As such, $w^T.x$ will be as large as possible\n",
        "=> Wi will tend to +infinity\n",
        "\n",
        "\n",
        "## Regularization:\n",
        "Regularization is a technique to solve the problem of overfitting in a machine learning algorithm by penalizing the cost function. It does so by using an additional penalty term in the cost function.\n",
        "There are two types of regularization techniques:\n",
        "1. Lasso or L1 Regularization\n",
        "2. Ridge or L2 Regularization (We will implement here)\n",
        "So, how can L2 Regularization help to prevent overfitting? Let’s first look at our new cost function:\n",
        "\n",
        "![](https://miro.medium.com/max/628/0*Nc_ocecF0dHpUutK)\n",
        "\n",
        "\n",
        "The regularization term will heavily penalize large $w_i$. The effect will be less on smaller $w_i$’s. As such, the growth of $w$ is controlled. The $h(x)$ we obtain with these controlled params $w$ will be more generalizable.\n",
        "\n",
        "**NOTE:** $λ$ is a hyper-parameter value. We have to find it using cross-validation. \n",
        "* Larger value $λ$ of will make $w_i$ shrink closer to $0$, which might lead to underfitting. \n",
        "* $λ = 0$, will have no regulariztion effect. \n",
        "\n",
        "When choosing $λ$, we have to take proper care of bias vs variance trade-off.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:31.755626Z",
          "iopub.status.busy": "2020-10-22T16:47:31.752338Z",
          "iopub.status.idle": "2020-10-22T16:47:31.759097Z",
          "shell.execute_reply": "2020-10-22T16:47:31.758490Z"
        },
        "id": "SIKhL69648U8",
        "papermill": {
          "duration": 0.052254,
          "end_time": "2020-10-22T16:47:31.759228",
          "exception": false,
          "start_time": "2020-10-22T16:47:31.706974",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class LogisticRegression(object):\n",
        "    \"\"\"\n",
        "    Logistic Regression Classifier\n",
        "    Parameters\n",
        "    ----------\n",
        "    learning_rate : int or float, default=0.1\n",
        "        The tuning parameter for the optimization algorithm (here, Gradient Descent) \n",
        "        that determines the step size at each iteration while moving toward a minimum \n",
        "        of the cost function.\n",
        "    max_iter : int, default=100\n",
        "        Maximum number of iterations taken for the optimization algorithm to converge\n",
        "    \n",
        "    penalty : None or 'l2', default='l2'.\n",
        "        Option to perform L2 regularization.\n",
        "    C : float, default=0.1\n",
        "        Inverse of regularization strength; must be a positive float. \n",
        "        Smaller values specify stronger regularization. \n",
        "    tolerance : float, optional, default=1e-4\n",
        "        Value indicating the weight change between epochs in which\n",
        "        gradient descent should terminated. \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=0.1, max_iter=100, regularization='l2', lambda_ = 10 , tolerance = 1e-4):\n",
        "        self.learning_rate  = learning_rate\n",
        "        self.max_iter       = max_iter\n",
        "        self.regularization = regularization\n",
        "        self.lambda_        = lambda_\n",
        "        self.tolerance      = tolerance\n",
        "        self.loss_log       = []\n",
        "    \n",
        "    def fit(self, X, y, verbose = False):\n",
        "        \"\"\"\n",
        "        Fit the model according to the given training data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "            Training vector, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target vector relative to X.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "        self.theta = np.random.rand(X.shape[1] + 1)\n",
        "        X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
        "        self.loss_log = []\n",
        "\n",
        "        for iteration in range(self.max_iter):\n",
        "            Z = np.matmul(X,  self.theta)\n",
        "            y_hat = self.__sigmoid(Z)\n",
        "            \n",
        "            errors = y_hat - y\n",
        "\n",
        "            N = X.shape[1] \n",
        "            \n",
        "            cost = (-1.0/N) * np.sum( y*np.log(y_hat) + (1.0 - y)*np.log(1.0-y_hat))\n",
        "            self.loss_log.append(cost)\n",
        "            \n",
        "            if verbose:\n",
        "                print(f'Iteration {iteration} Loss: {cost}')\n",
        "\n",
        "            if self.regularization is not None:\n",
        "                delta_grad = (1./N) *(np.matmul(errors.T, X)+ self.lambda_ * self.theta)\n",
        "            else:\n",
        "                delta_grad = (1./N) *(np.matmul(errors.T, X))\n",
        "                \n",
        "            self.theta -= self.learning_rate * delta_grad\n",
        "\n",
        "#             if np.all(abs(delta_grad) >= self.tolerance):\n",
        "#                 self.theta -= self.learning_rate * delta_grad\n",
        "#             else:\n",
        "#                 break\n",
        "                \n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Probability estimates for samples in X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Vector to be scored, where `n_samples` is the number of samples and\n",
        "            `n_features` is the number of features.\n",
        "        Returns\n",
        "        -------\n",
        "        probs : array-like of shape (n_samples,)\n",
        "            Returns the probability of each sample.\n",
        "        \"\"\"\n",
        "        return self.__sigmoid((X @ self.theta[1:]) + self.theta[0])\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict class labels for samples in X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array_like or sparse matrix, shape (n_samples, n_features)\n",
        "            Samples.\n",
        "        Returns\n",
        "        -------\n",
        "        labels : array, shape [n_samples]\n",
        "            Predicted class label per sample.\n",
        "        \"\"\"\n",
        "        return np.round(self.predict_proba(X))\n",
        "        \n",
        "    def __sigmoid(self, z):\n",
        "        \"\"\"\n",
        "        The sigmoid function.\n",
        "        Parameters\n",
        "        ------------\n",
        "        z : float\n",
        "            linear combinations of weights and sample features\n",
        "            z = w_0 + w_1*x_1 + ... + w_n*x_n\n",
        "        Returns\n",
        "        ---------\n",
        "        Value of logistic function at z\n",
        "        \"\"\"\n",
        "        return (1.0 / (1.0 + np.exp(-z)))\n",
        "\n",
        "    def get_params(self):\n",
        "        \"\"\"\n",
        "        Get method for models coeffients and intercept.\n",
        "        Returns\n",
        "        -------\n",
        "        params : dict\n",
        "        \"\"\"\n",
        "        try:\n",
        "            params = dict()\n",
        "            params['intercept'] = self.theta[0]\n",
        "            params['coef'] = self.theta[1:]\n",
        "            return params\n",
        "        except:\n",
        "            raise Exception('Fit the model first!')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eseYei7-48U_",
        "papermill": {
          "duration": 0.020105,
          "end_time": "2020-10-22T16:47:31.799342",
          "exception": false,
          "start_time": "2020-10-22T16:47:31.779237",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Train and Test Data Validation\n",
        "Let us split the whole data into two portion. We take 80% data in the train set and then put rest of the data into the test set to check the performance of the trained model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:31.852183Z",
          "iopub.status.busy": "2020-10-22T16:47:31.851332Z",
          "iopub.status.idle": "2020-10-22T16:47:32.144457Z",
          "shell.execute_reply": "2020-10-22T16:47:32.143708Z"
        },
        "id": "w1HSZLIW48VA",
        "papermill": {
          "duration": 0.325143,
          "end_time": "2020-10-22T16:47:32.144580",
          "exception": false,
          "start_time": "2020-10-22T16:47:31.819437",
          "status": "completed"
        },
        "tags": [],
        "outputId": "ba309f63-9197-47c4-ea31-5e0823d5c73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=42)\n",
        "\n",
        "# Train and Test Data Summary\n",
        "import plotly.graph_objects as go\n",
        "split = ['Train','Test']\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=split, y=[np.sum(y_train), np.sum(y_test)],#                base=[-500,-600],\n",
        "                    marker_color='crimson',\n",
        "                    name='Malignant'))\n",
        "fig.add_trace(go.Bar(x=split, \n",
        "                     y=[len(y_train)- np.sum(y_train), len(y_test) - np.sum(y_test)],\n",
        "                    base=0,\n",
        "                    marker_color='lightgreen',\n",
        "                    name='Benign'                ))\n",
        "fig.update_layout(width = 800, height = 400)\n",
        "fig.update_layout(title = 'Count of Samples in Train and Test Split', title_x = 0.5, xaxis_title = \"Category\", yaxis_title = 'Sample Count')\n",
        "fig.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"fda0da34-25b5-4b7d-a105-15d1ea4586c2\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"fda0da34-25b5-4b7d-a105-15d1ea4586c2\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'fda0da34-25b5-4b7d-a105-15d1ea4586c2',\n",
              "                        [{\"marker\": {\"color\": \"crimson\"}, \"name\": \"Malignant\", \"type\": \"bar\", \"x\": [\"Train\", \"Test\"], \"y\": [169, 43]}, {\"base\": 0, \"marker\": {\"color\": \"lightgreen\"}, \"name\": \"Benign\", \"type\": \"bar\", \"x\": [\"Train\", \"Test\"], \"y\": [286, 71]}],\n",
              "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Count of Samples in Train and Test Split\", \"x\": 0.5}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Category\"}}, \"yaxis\": {\"title\": {\"text\": \"Sample Count\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fda0da34-25b5-4b7d-a105-15d1ea4586c2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQpWR7UrBv3L",
        "papermill": {
          "duration": 0.021505,
          "end_time": "2020-10-22T16:47:32.188002",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.166497",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training Logistic Regression\n",
        "Now we train the logistic regression with the training data for a maximum interation of 200. Other parameters are kept default. Feel free to fiddle around the other parameters to understand more of them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:32.240152Z",
          "iopub.status.busy": "2020-10-22T16:47:32.239314Z",
          "iopub.status.idle": "2020-10-22T16:47:32.265567Z",
          "shell.execute_reply": "2020-10-22T16:47:32.266238Z"
        },
        "id": "q0egCbIh48VD",
        "papermill": {
          "duration": 0.056192,
          "end_time": "2020-10-22T16:47:32.266437",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.210245",
          "status": "completed"
        },
        "tags": [],
        "outputId": "50f42e15-a43d-4cd3-fb6f-90193ae00e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf = LogisticRegression(max_iter = 200, regularization= None)\n",
        "clf.fit(X_train, y_train, verbose = False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.LogisticRegression at 0x7f133ca67390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9u52S-aCJ-w",
        "papermill": {
          "duration": 0.021915,
          "end_time": "2020-10-22T16:47:32.310645",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.288730",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Plot Training Loss over Time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:32.364831Z",
          "iopub.status.busy": "2020-10-22T16:47:32.363946Z",
          "iopub.status.idle": "2020-10-22T16:47:32.392627Z",
          "shell.execute_reply": "2020-10-22T16:47:32.391829Z"
        },
        "id": "PkK3DdF2CJfi",
        "papermill": {
          "duration": 0.059776,
          "end_time": "2020-10-22T16:47:32.392756",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.332980",
          "status": "completed"
        },
        "tags": [],
        "outputId": "a43825f7-669b-4d74-be45-5a297329a2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "y = clf.loss_log \n",
        "\n",
        "fig = go.Figure(data=go.Scatter(x= np.arange(start =1, stop = len(y)), \n",
        "                                y=y,\n",
        "                                mode = 'lines+markers'))\n",
        "\n",
        "fig.update_layout(title = \"Error Plot over Iterations\", title_x = 0.5,\n",
        "                  xaxis_title = 'Iteration',\n",
        "                  yaxis_title = 'Log Loss',\n",
        "                  width = 800,\n",
        "                  height = 500)\n",
        "fig.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"cb736922-6d11-46c4-9644-d21d6e0b95cb\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"cb736922-6d11-46c4-9644-d21d6e0b95cb\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'cb736922-6d11-46c4-9644-d21d6e0b95cb',\n",
              "                        [{\"mode\": \"lines+markers\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [31.099886530219536, 15.225152395601606, 8.411415879755781, 7.841773652298919, 7.544889908570199, 7.276798039781106, 7.033281922128887, 6.811259622469454, 6.608102849411072, 6.421565235923779, 6.2497223803396755, 6.090920929817228, 5.943735792474993, 5.80693438718859, 5.6794468569660985, 5.56034127004238, 5.448802960432153, 5.344117289598059, 5.245655230465898, 5.152861279427322, 5.065243290400199, 4.982363898549322, 4.90383326173292, 4.829302897126388, 4.758460430665561, 4.6910251096065405, 4.626743955024907, 4.5653884526411, 4.506751697914633, 4.450645925670661, 4.3969003662312796, 4.345359379621527, 4.295880827308388, 4.24833464743273, 4.202601604868199, 4.158572191896044, 4.116145658988626, 4.0752291582823705, 4.03573698490318, 3.997589903472426, 3.960714548942333, 3.925042892444653, 3.8905117641343203, 3.8570624261098807, 3.8246401894273863, 3.793194070020938, 3.7626764790233422, 3.7330429435627384, 3.7042518546108267, 3.676264238888205, 3.6490435522028264, 3.622555491917783, 3.596767826521687, 3.571650240515419, 3.547174193038006, 3.5233127888364484, 3.500040660343214, 3.4773338597640397, 3.455169760200369, 3.433526964937557, 3.4123852241238595, 3.391725358147875, 3.371529187095053, 3.351779465728294, 3.3324598234946863, 3.313554709110958, 3.2950493393250615, 3.2769296514912067, 3.259182259631127, 3.24179441368604, 3.224753961691996, 3.208049314636575, 3.1916694137775092, 3.1756037002240713, 3.159842086600249, 3.144374930625091, 3.129193010460304, 3.114287501688422, 3.099649955796823, 3.0852722800536694, 3.0711467186715535, 3.0572658351635016, 3.0436224958039486, 3.030209854114552, 3.0170213363012928, 3.0040506275752827, 2.9912916592951366, 2.9787385968737214, 2.9663858283965974, 2.954227953903581, 2.942259775288624, 2.9304762867766243, 2.918872665938939, 2.9074442652122188, 2.8961866038878497, 2.8850953605416727, 2.8741663658758902, 2.8633955959470767, 2.8527791657561283, 2.8423133231776423, 2.8319944432078685, 2.8218190225117827, 2.811783674251207, 2.801885123177138, 2.7921202009705803, 2.7824858418172607, 2.7729790782025474, 2.7635970369138545, 2.7543369352385905, 2.745196077346541, 2.7361718508462585, 2.7272617235057224, 2.718463240128149, 2.709774019574395, 2.701191751923948, 2.692714195766999, 2.684339175620536, 2.6760645794618387, 2.6678883563731826, 2.659808514291868, 2.651823117860135, 2.6439302863697467, 2.6361281917964186, 2.628415056919494, 2.6207891535225656, 2.613248800670972, 2.605792363062346, 2.5984182494465924, 2.591124911111895, 2.5839108404335285, 2.576774569482435, 2.5697146686906938, 2.5627297455711773, 2.555818443488806, 2.548979440480997, 2.542211448124995, 2.5355132104499103, 2.5288835028914076, 2.5223211312870903, 2.5158249309107337, 2.5093937655436043, 2.503026526581213, 2.4967221321739173, 2.4904795263998647, 2.484297678468878, 2.478175581955908, 2.472112254062779, 2.4661067349070085, 2.4601580868365396, 2.4542653937692815, 2.4484277605564024, 2.4426443123683907, 2.436914194102919, 2.431236569813611, 2.4256106221588487, 2.4200355518697965, 2.41451057723686, 2.4090349336138313, 2.4036078729390047, 2.3982286632725947, 2.3928965883497915, 2.3876109471488483, 2.3823710534736025, 2.377176235549866, 2.3720258356351502, 2.366919209641208, 2.361855726768892, 2.356834769154872, 2.3518557315297555, 2.3469180208871747, 2.3420210561634343, 2.3371642679273252, 2.332347098079725, 2.32756899956262, 2.3228294360772135, 2.3181278818107707, 2.3134638211719047, 2.308836748533976, 2.304246167986333, 2.299691593093096, 2.295172546659236, 2.290688560503666, 2.2862391752391216, 2.2818239400585765, 2.2774424125279764, 2.273094158385059, 2.2687787513440676, 2.2644957729061446, 2.260244812175208, 2.2560254656791403, 2.2518373371960902, 2.247680037585734, 2.243553184625317, 2.239456402850328, 2.235389323399634, 2.2313515838649596, 2.227342828144532, 2.223362706300787, 2.2194108744219827, 2.215486994487611]}],\n",
              "                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Error Plot over Iterations\", \"x\": 0.5}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Iteration\"}}, \"yaxis\": {\"title\": {\"text\": \"Log Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cb736922-6d11-46c4-9644-d21d6e0b95cb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50y75O6BDRAg",
        "papermill": {
          "duration": 0.022832,
          "end_time": "2020-10-22T16:47:32.439335",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.416503",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Accuracy Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:32.498195Z",
          "iopub.status.busy": "2020-10-22T16:47:32.496889Z",
          "iopub.status.idle": "2020-10-22T16:47:32.500888Z",
          "shell.execute_reply": "2020-10-22T16:47:32.501531Z"
        },
        "id": "vG00BWel48VH",
        "papermill": {
          "duration": 0.037999,
          "end_time": "2020-10-22T16:47:32.501714",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.463715",
          "status": "completed"
        },
        "tags": [],
        "outputId": "9449cfa0-832e-4c8f-fb0d-ff68b21e658b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "match = (y_pred == y_test)*1.0\n",
        "match.values\n",
        "\n",
        "\n",
        "accuracy = (np.sum(match)*100/ len(match))\n",
        "print(f'Accuracy {accuracy}%')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 96.49122807017544%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj3YQZaHEmlX",
        "papermill": {
          "duration": 0.024196,
          "end_time": "2020-10-22T16:47:32.549844",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.525648",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Plot Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-22T16:47:32.604509Z",
          "iopub.status.busy": "2020-10-22T16:47:32.603685Z",
          "iopub.status.idle": "2020-10-22T16:47:33.015052Z",
          "shell.execute_reply": "2020-10-22T16:47:33.014270Z"
        },
        "id": "2EovXZHzEGyo",
        "papermill": {
          "duration": 0.441459,
          "end_time": "2020-10-22T16:47:33.015204",
          "exception": false,
          "start_time": "2020-10-22T16:47:32.573745",
          "status": "completed"
        },
        "tags": [],
        "outputId": "218df395-0e7b-4b1d-dd79-b090f2f07bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[70  1]\n",
            " [ 3 40]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f132abe0c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSM73lMREQs9",
        "papermill": {
          "duration": 0.025119,
          "end_time": "2020-10-22T16:47:33.065994",
          "exception": false,
          "start_time": "2020-10-22T16:47:33.040875",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}